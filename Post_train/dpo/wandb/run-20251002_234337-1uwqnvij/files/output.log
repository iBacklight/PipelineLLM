[34m[1mwandb[0m: Detected [huggingface_hub.inference, openai] in use.
[34m[1mwandb[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
[34m[1mwandb[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/
2025-10-02 23:43:38,462 - INFO - Wandb initialized: https://wandb.ai/ibacklight/qwen3-dpo-training/runs/1uwqnvij
2025-10-02 23:43:38,463 - INFO - Loading model and tokenizer...
==((====))==  Unsloth 2025.9.9: Fast Qwen3 patching. Transformers: 4.56.2. vLLM: 0.10.2.
   \\   /|    NVIDIA GeForce RTX 4080. Num GPUs = 1. Max memory: 15.694 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.8.0+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.4.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post1. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.01.
Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.
Unsloth 2025.9.9 patched 28 layers with 0 QKV layers, 0 O layers and 0 MLP layers.
2025-10-02 23:43:44,031 - INFO - Model and tokenizer loaded successfully!
2025-10-02 23:43:44,034 - INFO - Model parameters: 34865152 trainable
2025-10-02 23:43:44,034 - INFO - Loading datasets...
2025-10-02 23:43:44,037 - INFO - Loaded train dataset: 7333 samples
2025-10-02 23:43:44,037 - INFO - Loaded eval dataset: 150 samples
2025-10-02 23:43:44,037 - INFO - Sample data keys: ['prompt', 'chosen', 'rejected']
2025-10-02 23:43:44,104 - INFO - Creating DPOTrainer...
2025-10-02 23:43:44,513 - INFO - Training configuration:
2025-10-02 23:43:44,514 - INFO -   Model: unsloth/Qwen3-1.7B-unsloth-bnb-4bit
2025-10-02 23:43:44,514 - INFO -   Train samples: 7333
2025-10-02 23:43:44,514 - INFO -   Eval samples: 150
2025-10-02 23:43:44,514 - INFO -   Batch size: 1
2025-10-02 23:43:44,515 - INFO -   Gradient accumulation: 16
2025-10-02 23:43:44,515 - INFO -   Learning rate: 1e-05
2025-10-02 23:43:44,515 - INFO -   Epochs: 1
2025-10-02 23:43:44,515 - INFO -   Beta: 0.1
2025-10-02 23:43:44,515 - INFO -   Max length: 1024
2025-10-02 23:43:44,515 - INFO - Starting training...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None}.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,333 | Num Epochs = 1 | Total steps = 459
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 16
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 16 x 1) = 16
 "-____-"     Trainable parameters = 34,865,152 of 1,755,440,128 (1.99% trained)
                                                                                                                                                              
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.6912, 'grad_norm': 15.457469940185547, 'learning_rate': 1.956521739130435e-06, 'rewards/chosen': -0.0021919249556958675, 'rewards/rejected': -0.010478973388671875, 'rewards/accuracies': 0.22499999403953552, 'rewards/margins': 0.008305358700454235, 'logps/chosen': -412.7992248535156, 'logps/rejected': -369.2578125, 'logits/chosen': 0.11483617126941681, 'logits/rejected': 0.5036399960517883, 'epoch': 0.02}
{'loss': 0.6868, 'grad_norm': 14.112536430358887, 'learning_rate': 4.130434782608696e-06, 'rewards/chosen': 0.05974273756146431, 'rewards/rejected': 0.033313751220703125, 'rewards/accuracies': 0.28125, 'rewards/margins': 0.02642364427447319, 'logps/chosen': -470.22344970703125, 'logps/rejected': -381.44451904296875, 'logits/chosen': 0.1589973419904709, 'logits/rejected': 0.4661460816860199, 'epoch': 0.04}
{'loss': 0.6695, 'grad_norm': 17.30943489074707, 'learning_rate': 6.304347826086958e-06, 'rewards/chosen': 0.2052989900112152, 'rewards/rejected': 0.12607498466968536, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': 0.07923431694507599, 'logps/chosen': -483.83514404296875, 'logps/rejected': -382.5015563964844, 'logits/chosen': 0.015227031894028187, 'logits/rejected': 0.5053901672363281, 'epoch': 0.07}
{'loss': 0.6655, 'grad_norm': 13.143753051757812, 'learning_rate': 8.478260869565218e-06, 'rewards/chosen': 0.40714186429977417, 'rewards/rejected': 0.3104133605957031, 'rewards/accuracies': 0.48124998807907104, 'rewards/margins': 0.09675140678882599, 'logps/chosen': -460.5796813964844, 'logps/rejected': -359.61407470703125, 'logits/chosen': 0.37825337052345276, 'logits/rejected': 0.6583238840103149, 'epoch': 0.09}
{'loss': 0.6611, 'grad_norm': 11.684126853942871, 'learning_rate': 9.998698142908954e-06, 'rewards/chosen': 0.7791396975517273, 'rewards/rejected': 0.6430778503417969, 'rewards/accuracies': 0.512499988079071, 'rewards/margins': 0.13605423271656036, 'logps/chosen': -436.51251220703125, 'logps/rejected': -412.7906188964844, 'logits/chosen': 0.16202564537525177, 'logits/rejected': 0.6238511204719543, 'epoch': 0.11}
                                                                                                                                                              
{'eval_loss': 0.6346353888511658, 'eval_runtime': 24.9531, 'eval_samples_per_second': 6.011, 'eval_steps_per_second': 6.011, 'eval_rewards/chosen': 0.8881404399871826, 'eval_rewards/rejected': 0.6566455364227295, 'eval_rewards/accuracies': 0.5533333420753479, 'eval_rewards/margins': 0.2313753217458725, 'eval_logps/chosen': -426.7583312988281, 'eval_logps/rejected': -359.76165771484375, 'eval_logits/chosen': 0.3175813853740692, 'eval_logits/rejected': 0.657838761806488, 'epoch': 0.11}
{'loss': 0.6043, 'grad_norm': 15.199386596679688, 'learning_rate': 9.975572871372513e-06, 'rewards/chosen': 0.9891692996025085, 'rewards/rejected': 0.6700195074081421, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 0.31925201416015625, 'logps/chosen': -437.23126220703125, 'logps/rejected': -358.703125, 'logits/chosen': 0.22492066025733948, 'logits/rejected': 0.6022598147392273, 'epoch': 0.13}
{'loss': 0.6338, 'grad_norm': 13.974677085876465, 'learning_rate': 9.923671408622128e-06, 'rewards/chosen': 1.0863205194473267, 'rewards/rejected': 0.7884605526924133, 'rewards/accuracies': 0.543749988079071, 'rewards/margins': 0.29792481660842896, 'logps/chosen': -419.640625, 'logps/rejected': -360.3218688964844, 'logits/chosen': 0.24901524186134338, 'logits/rejected': 0.6013679504394531, 'epoch': 0.15}
{'loss': 0.6394, 'grad_norm': 13.605116844177246, 'learning_rate': 9.843293926407866e-06, 'rewards/chosen': 1.1161201000213623, 'rewards/rejected': 0.842389702796936, 'rewards/accuracies': 0.581250011920929, 'rewards/margins': 0.2738037109375, 'logps/chosen': -441.37811279296875, 'logps/rejected': -389.8531188964844, 'logits/chosen': 0.3198574185371399, 'logits/rejected': 0.5022648572921753, 'epoch': 0.17}
{'loss': 0.6164, 'grad_norm': 11.46572208404541, 'learning_rate': 9.734905287340985e-06, 'rewards/chosen': 1.0854820013046265, 'rewards/rejected': 0.689776599407196, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 0.3958679139614105, 'logps/chosen': -437.4453125, 'logps/rejected': -388.02655029296875, 'logits/chosen': 0.1984456479549408, 'logits/rejected': 0.5846092104911804, 'epoch': 0.2}
{'loss': 0.6402, 'grad_norm': 20.236770629882812, 'learning_rate': 9.599132356364247e-06, 'rewards/chosen': 0.8275039792060852, 'rewards/rejected': 0.5467460751533508, 'rewards/accuracies': 0.543749988079071, 'rewards/margins': 0.2807052731513977, 'logps/chosen': -425.9296875, 'logps/rejected': -398.5218811035156, 'logits/chosen': 0.1068599671125412, 'logits/rejected': 0.4003259539604187, 'epoch': 0.22}
{'eval_loss': 0.6013191938400269, 'eval_runtime': 24.6791, 'eval_samples_per_second': 6.078, 'eval_steps_per_second': 6.078, 'eval_rewards/chosen': 0.7473962306976318, 'eval_rewards/rejected': 0.3632975220680237, 'eval_rewards/accuracies': 0.54666668176651, 'eval_rewards/margins': 0.3841194808483124, 'eval_logps/chosen': -428.163330078125, 'eval_logps/rejected': -362.6916809082031, 'eval_logits/chosen': 0.13048502802848816, 'eval_logits/rejected': 0.4771524965763092, 'epoch': 0.22}
{'loss': 0.6868, 'grad_norm': 11.598146438598633, 'learning_rate': 9.436760375282858e-06, 'rewards/chosen': 0.7381798028945923, 'rewards/rejected': 0.4343116879463196, 'rewards/accuracies': 0.5562499761581421, 'rewards/margins': 0.3041572570800781, 'logps/chosen': -424.390625, 'logps/rejected': -411.72186279296875, 'logits/chosen': 0.06056366115808487, 'logits/rejected': 0.5026203393936157, 'epoch': 0.24}
{'loss': 0.6458, 'grad_norm': 20.602581024169922, 'learning_rate': 9.24872842132394e-06, 'rewards/chosen': 0.8341079950332642, 'rewards/rejected': 0.523730456829071, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 0.3103698790073395, 'logps/chosen': -426.84844970703125, 'logps/rejected': -389.8265686035156, 'logits/chosen': 0.13839149475097656, 'logits/rejected': 0.3410015106201172, 'epoch': 0.26}
{'loss': 0.5897, 'grad_norm': 20.437414169311523, 'learning_rate': 9.036123975989893e-06, 'rewards/chosen': 0.9088714718818665, 'rewards/rejected': 0.5014961361885071, 'rewards/accuracies': 0.581250011920929, 'rewards/margins': 0.4073982238769531, 'logps/chosen': -443.9671936035156, 'logps/rejected': -373.30157470703125, 'logits/chosen': -0.07058410346508026, 'logits/rejected': 0.3308876156806946, 'epoch': 0.28}
{'loss': 0.5599, 'grad_norm': 11.833600044250488, 'learning_rate': 8.800176635616658e-06, 'rewards/chosen': 1.084539771080017, 'rewards/rejected': 0.5212043523788452, 'rewards/accuracies': 0.6625000238418579, 'rewards/margins': 0.563428521156311, 'logps/chosen': -452.8125, 'logps/rejected': -372.03125, 'logits/chosen': 0.1052345260977745, 'logits/rejected': 0.554019570350647, 'epoch': 0.31}
{'loss': 0.6071, 'grad_norm': 14.29430103302002, 'learning_rate': 8.54225100001184e-06, 'rewards/chosen': 1.1444488763809204, 'rewards/rejected': 0.6570510864257812, 'rewards/accuracies': 0.59375, 'rewards/margins': 0.48764342069625854, 'logps/chosen': -443.1953125, 'logps/rejected': -393.12969970703125, 'logits/chosen': 0.34619981050491333, 'logits/rejected': 0.7082748413085938, 'epoch': 0.33}
{'eval_loss': 0.5924469232559204, 'eval_runtime': 23.2965, 'eval_samples_per_second': 6.439, 'eval_steps_per_second': 6.439, 'eval_rewards/chosen': 1.1320915222167969, 'eval_rewards/rejected': 0.6379215717315674, 'eval_rewards/accuracies': 0.5933333039283752, 'eval_rewards/margins': 0.49440428614616394, 'eval_logps/chosen': -424.31500244140625, 'eval_logps/rejected': -359.9466552734375, 'eval_logits/chosen': 0.27919188141822815, 'eval_logits/rejected': 0.6072208881378174, 'epoch': 0.33}
{'loss': 0.5911, 'grad_norm': 14.418580055236816, 'learning_rate': 8.263838780301182e-06, 'rewards/chosen': 0.9565628170967102, 'rewards/rejected': 0.5064125061035156, 'rewards/accuracies': 0.5562499761581421, 'rewards/margins': 0.4501327574253082, 'logps/chosen': -416.57342529296875, 'logps/rejected': -373.8218688964844, 'logits/chosen': 0.09630946815013885, 'logits/rejected': 0.582288920879364, 'epoch': 0.35}
{'loss': 0.5961, 'grad_norm': 17.766311645507812, 'learning_rate': 7.966550171627592e-06, 'rewards/chosen': 0.9985283017158508, 'rewards/rejected': 0.5536483526229858, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 0.445089727640152, 'logps/chosen': -430.85467529296875, 'logps/rejected': -389.703125, 'logits/chosen': 0.20161715149879456, 'logits/rejected': 0.7493957281112671, 'epoch': 0.37}
{'loss': 0.5923, 'grad_norm': 13.101689338684082, 'learning_rate': 7.652104540598712e-06, 'rewards/chosen': 0.957836925983429, 'rewards/rejected': 0.4629226624965668, 'rewards/accuracies': 0.5874999761581421, 'rewards/margins': 0.494943231344223, 'logps/chosen': -430.82342529296875, 'logps/rejected': -357.5703125, 'logits/chosen': 0.14296379685401917, 'logits/rejected': 0.5608524084091187, 'epoch': 0.39}
{'loss': 0.5774, 'grad_norm': 13.643181800842285, 'learning_rate': 7.322320481342053e-06, 'rewards/chosen': 1.1620811223983765, 'rewards/rejected': 0.6050826907157898, 'rewards/accuracies': 0.5874999761581421, 'rewards/margins': 0.5568679571151733, 'logps/chosen': -465.60626220703125, 'logps/rejected': -397.2328186035156, 'logits/chosen': 0.3405386805534363, 'logits/rejected': 0.637858510017395, 'epoch': 0.41}
{'loss': 0.5929, 'grad_norm': 14.912424087524414, 'learning_rate': 6.979105297678462e-06, 'rewards/chosen': 1.06878662109375, 'rewards/rejected': 0.5477851629257202, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5206626653671265, 'logps/chosen': -457.7328186035156, 'logps/rejected': -376.0015563964844, 'logits/chosen': 0.25739938020706177, 'logits/rejected': 0.7477470636367798, 'epoch': 0.44}
{'eval_loss': 0.5976850390434265, 'eval_runtime': 25.4257, 'eval_samples_per_second': 5.9, 'eval_steps_per_second': 5.9, 'eval_rewards/chosen': 1.0379704236984253, 'eval_rewards/rejected': 0.5303369164466858, 'eval_rewards/accuracies': 0.5666666626930237, 'eval_rewards/margins': 0.507703423500061, 'eval_logps/chosen': -425.2541809082031, 'eval_logps/rejected': -361.02166748046875, 'eval_logits/chosen': 0.2903924584388733, 'eval_logits/rejected': 0.6108142137527466, 'epoch': 0.44}
{'loss': 0.6147, 'grad_norm': 12.231678009033203, 'learning_rate': 6.6244439722436985e-06, 'rewards/chosen': 0.9769546389579773, 'rewards/rejected': 0.5605018734931946, 'rewards/accuracies': 0.5687500238418579, 'rewards/margins': 0.41665345430374146, 'logps/chosen': -416.515625, 'logps/rejected': -404.609375, 'logits/chosen': 0.19943276047706604, 'logits/rejected': 0.5495861172676086, 'epoch': 0.46}
{'loss': 0.6168, 'grad_norm': 16.67693519592285, 'learning_rate': 6.260387686355121e-06, 'rewards/chosen': 0.8318710327148438, 'rewards/rejected': 0.43524399399757385, 'rewards/accuracies': 0.5562499761581421, 'rewards/margins': 0.396536260843277, 'logps/chosen': -454.7578125, 'logps/rejected': -426.6875, 'logits/chosen': 0.002873754594475031, 'logits/rejected': 0.38829725980758667, 'epoch': 0.48}
{'loss': 0.5882, 'grad_norm': 10.099101066589355, 'learning_rate': 5.889041957018745e-06, 'rewards/chosen': 0.8605697751045227, 'rewards/rejected': 0.39119261503219604, 'rewards/accuracies': 0.612500011920929, 'rewards/margins': 0.46953123807907104, 'logps/chosen': -456.1625061035156, 'logps/rejected': -379.5625, 'logits/chosen': -0.023596692830324173, 'logits/rejected': 0.324812114238739, 'epoch': 0.5}
{'loss': 0.5627, 'grad_norm': 10.1799955368042, 'learning_rate': 5.5125544596862505e-06, 'rewards/chosen': 1.1248458623886108, 'rewards/rejected': 0.5189071893692017, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6061981320381165, 'logps/chosen': -423.44842529296875, 'logps/rejected': -387.94921875, 'logits/chosen': 0.12058258056640625, 'logits/rejected': 0.5318414568901062, 'epoch': 0.52}
{'loss': 0.6043, 'grad_norm': 11.602076530456543, 'learning_rate': 5.133102607188875e-06, 'rewards/chosen': 1.0330359935760498, 'rewards/rejected': 0.5646759271621704, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 0.468423455953598, 'logps/chosen': -440.4281311035156, 'logps/rejected': -414.9195251464844, 'logits/chosen': 0.06562785804271698, 'logits/rejected': 0.27080637216567993, 'epoch': 0.55}
{'eval_loss': 0.5896292328834534, 'eval_runtime': 25.7458, 'eval_samples_per_second': 5.826, 'eval_steps_per_second': 5.826, 'eval_rewards/chosen': 1.0635042190551758, 'eval_rewards/rejected': 0.5027750730514526, 'eval_rewards/accuracies': 0.5799999833106995, 'eval_rewards/margins': 0.5603987574577332, 'eval_logps/chosen': -425.00250244140625, 'eval_logps/rejected': -361.2966613769531, 'eval_logits/chosen': 0.2525978684425354, 'eval_logits/rejected': 0.5760738253593445, 'epoch': 0.55}
{'loss': 0.5714, 'grad_norm': 12.765832901000977, 'learning_rate': 4.752880956685407e-06, 'rewards/chosen': 1.0749168395996094, 'rewards/rejected': 0.5056312680244446, 'rewards/accuracies': 0.606249988079071, 'rewards/margins': 0.5691497921943665, 'logps/chosen': -416.5531311035156, 'logps/rejected': -346.2124938964844, 'logits/chosen': 0.16355066001415253, 'logits/rejected': 0.5489246249198914, 'epoch': 0.57}
{'loss': 0.5749, 'grad_norm': 13.061521530151367, 'learning_rate': 4.374088517456074e-06, 'rewards/chosen': 1.1792914867401123, 'rewards/rejected': 0.6591957211494446, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5200973749160767, 'logps/chosen': -451.1625061035156, 'logps/rejected': -388.9820251464844, 'logits/chosen': 0.1384422332048416, 'logits/rejected': 0.42358094453811646, 'epoch': 0.59}
{'loss': 0.5886, 'grad_norm': 12.736177444458008, 'learning_rate': 3.998916032947594e-06, 'rewards/chosen': 1.2699248790740967, 'rewards/rejected': 0.7134895324707031, 'rewards/accuracies': 0.6312500238418579, 'rewards/margins': 0.5564788579940796, 'logps/chosen': -432.47967529296875, 'logps/rejected': -356.8062438964844, 'logits/chosen': 0.24631920456886292, 'logits/rejected': 0.5009757876396179, 'epoch': 0.61}
{'loss': 0.6108, 'grad_norm': 15.586723327636719, 'learning_rate': 3.629533310623658e-06, 'rewards/chosen': 1.191229224205017, 'rewards/rejected': 0.6769210696220398, 'rewards/accuracies': 0.5562499761581421, 'rewards/margins': 0.5140770077705383, 'logps/chosen': -429.5390625, 'logps/rejected': -371.421875, 'logits/chosen': 0.3271145522594452, 'logits/rejected': 0.43528109788894653, 'epoch': 0.63}
{'loss': 0.5952, 'grad_norm': 22.876583099365234, 'learning_rate': 3.268076672898492e-06, 'rewards/chosen': 1.1824172735214233, 'rewards/rejected': 0.5942138433456421, 'rewards/accuracies': 0.5625, 'rewards/margins': 0.588696300983429, 'logps/chosen': -442.1000061035156, 'logps/rejected': -382.3531188964844, 'logits/chosen': 0.2990381121635437, 'logits/rejected': 0.540783703327179, 'epoch': 0.65}
{'eval_loss': 0.5914261937141418, 'eval_runtime': 25.1245, 'eval_samples_per_second': 5.97, 'eval_steps_per_second': 5.97, 'eval_rewards/chosen': 1.2276692390441895, 'eval_rewards/rejected': 0.6409944891929626, 'eval_rewards/accuracies': 0.5933333039283752, 'eval_rewards/margins': 0.5865917801856995, 'eval_logps/chosen': -423.3566589355469, 'eval_logps/rejected': -359.9166564941406, 'eval_logits/chosen': 0.3228019177913666, 'eval_logits/rejected': 0.6411173343658447, 'epoch': 0.65}
{'loss': 0.6407, 'grad_norm': 13.004953384399414, 'learning_rate': 2.91663660173098e-06, 'rewards/chosen': 1.0890343189239502, 'rewards/rejected': 0.6896354556083679, 'rewards/accuracies': 0.59375, 'rewards/margins': 0.3994148373603821, 'logps/chosen': -395.24688720703125, 'logps/rejected': -390.21405029296875, 'logits/chosen': 0.28843003511428833, 'logits/rejected': 0.4875297546386719, 'epoch': 0.68}
{'loss': 0.5637, 'grad_norm': 11.881149291992188, 'learning_rate': 2.57724564833675e-06, 'rewards/chosen': 1.1596992015838623, 'rewards/rejected': 0.5456771850585938, 'rewards/accuracies': 0.699999988079071, 'rewards/margins': 0.6141548156738281, 'logps/chosen': -436.1265563964844, 'logps/rejected': -366.8125, 'logits/chosen': 0.3504064679145813, 'logits/rejected': 0.6770221590995789, 'epoch': 0.7}
{'loss': 0.6115, 'grad_norm': 13.296767234802246, 'learning_rate': 2.2518666779423078e-06, 'rewards/chosen': 0.951245129108429, 'rewards/rejected': 0.33953094482421875, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 0.6117622256278992, 'logps/chosen': -420.80938720703125, 'logps/rejected': -431.40625, 'logits/chosen': 0.145832821726799, 'logits/rejected': 0.5973350405693054, 'epoch': 0.72}
{'loss': 0.5896, 'grad_norm': 16.363304138183594, 'learning_rate': 1.9423815175676027e-06, 'rewards/chosen': 1.196162462234497, 'rewards/rejected': 0.6196304559707642, 'rewards/accuracies': 0.637499988079071, 'rewards/margins': 0.5767974853515625, 'logps/chosen': -422.87969970703125, 'logps/rejected': -368.31951904296875, 'logits/chosen': 0.18138599395751953, 'logits/rejected': 0.5213874578475952, 'epoch': 0.74}
{'loss': 0.5689, 'grad_norm': 17.339427947998047, 'learning_rate': 1.650580072492496e-06, 'rewards/chosen': 1.0310653448104858, 'rewards/rejected': 0.4410461485385895, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 0.5900596380233765, 'logps/chosen': -452.2093811035156, 'logps/rejected': -398.42498779296875, 'logits/chosen': 0.293283075094223, 'logits/rejected': 0.6861404180526733, 'epoch': 0.76}
{'eval_loss': 0.5971049070358276, 'eval_runtime': 24.9599, 'eval_samples_per_second': 6.01, 'eval_steps_per_second': 6.01, 'eval_rewards/chosen': 1.0544148683547974, 'eval_rewards/rejected': 0.4992659389972687, 'eval_rewards/accuracies': 0.6066666841506958, 'eval_rewards/margins': 0.5548925995826721, 'eval_logps/chosen': -425.0924987792969, 'eval_logps/rejected': -361.3316650390625, 'eval_logits/chosen': 0.2999875843524933, 'eval_logits/rejected': 0.6186999678611755, 'epoch': 0.76}
{'loss': 0.6026, 'grad_norm': 10.080132484436035, 'learning_rate': 1.3781499743519911e-06, 'rewards/chosen': 1.175506591796875, 'rewards/rejected': 0.6189239621162415, 'rewards/accuracies': 0.5874999761581421, 'rewards/margins': 0.556384265422821, 'logps/chosen': -447.8828125, 'logps/rejected': -397.2124938964844, 'logits/chosen': 0.1117059737443924, 'logits/rejected': 0.42591628432273865, 'epoch': 0.79}
{'loss': 0.6268, 'grad_norm': 16.046058654785156, 'learning_rate': 1.126666820730366e-06, 'rewards/chosen': 0.9825904965400696, 'rewards/rejected': 0.5277595520019531, 'rewards/accuracies': 0.5687500238418579, 'rewards/margins': 0.45469436049461365, 'logps/chosen': -440.328125, 'logps/rejected': -395.08123779296875, 'logits/chosen': 0.23437395691871643, 'logits/rejected': 0.5332477688789368, 'epoch': 0.81}
{'loss': 0.6105, 'grad_norm': 11.202855110168457, 'learning_rate': 8.975850627034605e-07, 'rewards/chosen': 0.9065612554550171, 'rewards/rejected': 0.49711838364601135, 'rewards/accuracies': 0.6187499761581421, 'rewards/margins': 0.40966796875, 'logps/chosen': -417.84375, 'logps/rejected': -401.3687438964844, 'logits/chosen': 0.07684383541345596, 'logits/rejected': 0.3904399871826172, 'epoch': 0.83}
{'loss': 0.6095, 'grad_norm': 13.820693016052246, 'learning_rate': 6.922295930309691e-07, 'rewards/chosen': 0.9965164065361023, 'rewards/rejected': 0.5379989743232727, 'rewards/accuracies': 0.5625, 'rewards/margins': 0.45873260498046875, 'logps/chosen': -452.21875, 'logps/rejected': -392.20623779296875, 'logits/chosen': 0.4463077187538147, 'logits/rejected': 0.6087222099304199, 'epoch': 0.85}
{'loss': 0.5889, 'grad_norm': 14.2245512008667, 'learning_rate': 5.117880836483452e-07, 'rewards/chosen': 1.0271705389022827, 'rewards/rejected': 0.4483932554721832, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5787101984024048, 'logps/chosen': -431.88592529296875, 'logps/rejected': -389.6031188964844, 'logits/chosen': 0.22183164954185486, 'logits/rejected': 0.6136608123779297, 'epoch': 0.87}
{'eval_loss': 0.5840504765510559, 'eval_runtime': 24.9156, 'eval_samples_per_second': 6.02, 'eval_steps_per_second': 6.02, 'eval_rewards/chosen': 1.0292822122573853, 'eval_rewards/rejected': 0.44997313618659973, 'eval_rewards/accuracies': 0.5933333039283752, 'eval_rewards/margins': 0.5793392062187195, 'eval_logps/chosen': -425.34417724609375, 'eval_logps/rejected': -361.82501220703125, 'eval_logits/chosen': 0.27663615345954895, 'eval_logits/rejected': 0.5969954133033752, 'epoch': 0.87}
{'loss': 0.5634, 'grad_norm': 12.013134002685547, 'learning_rate': 3.5730411677439125e-07, 'rewards/chosen': 1.1169929504394531, 'rewards/rejected': 0.4204307496547699, 'rewards/accuracies': 0.637499988079071, 'rewards/margins': 0.6967048645019531, 'logps/chosen': -432.6796875, 'logps/rejected': -376.6109313964844, 'logits/chosen': 0.17765751481056213, 'logits/rejected': 0.6219471096992493, 'epoch': 0.89}
{'loss': 0.5241, 'grad_norm': 10.437424659729004, 'learning_rate': 2.2967114936073342e-07, 'rewards/chosen': 1.2551918029785156, 'rewards/rejected': 0.475137323141098, 'rewards/accuracies': 0.675000011920929, 'rewards/margins': 0.7798980474472046, 'logps/chosen': -468.42657470703125, 'logps/rejected': -369.5234375, 'logits/chosen': 0.3948987126350403, 'logits/rejected': 0.7907150387763977, 'epoch': 0.92}
{'loss': 0.5594, 'grad_norm': 11.152959823608398, 'learning_rate': 1.2962734578973568e-07, 'rewards/chosen': 1.111920952796936, 'rewards/rejected': 0.4765434265136719, 'rewards/accuracies': 0.643750011920929, 'rewards/margins': 0.6353759765625, 'logps/chosen': -430.19061279296875, 'logps/rejected': -375.390625, 'logits/chosen': 0.1386951506137848, 'logits/rejected': 0.4383651614189148, 'epoch': 0.94}
{'loss': 0.5761, 'grad_norm': 21.016817092895508, 'learning_rate': 5.775130870590784e-08, 'rewards/chosen': 1.0646682977676392, 'rewards/rejected': 0.42090147733688354, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 0.6438919305801392, 'logps/chosen': -461.8828125, 'logps/rejected': -390.6859436035156, 'logits/chosen': 0.1921750009059906, 'logits/rejected': 0.6130657196044922, 'epoch': 0.96}
{'loss': 0.5941, 'grad_norm': 16.22281265258789, 'learning_rate': 1.4458732671523978e-08, 'rewards/chosen': 0.9542800784111023, 'rewards/rejected': 0.506701648235321, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 0.44781798124313354, 'logps/chosen': -435.26251220703125, 'logps/rejected': -395.44842529296875, 'logits/chosen': 0.13083171844482422, 'logits/rejected': 0.4642166197299957, 'epoch': 0.98}
{'eval_loss': 0.5887914299964905, 'eval_runtime': 24.9334, 'eval_samples_per_second': 6.016, 'eval_steps_per_second': 6.016, 'eval_rewards/chosen': 1.027356743812561, 'eval_rewards/rejected': 0.4704833924770355, 'eval_rewards/accuracies': 0.5866666436195374, 'eval_rewards/margins': 0.5566633939743042, 'eval_logps/chosen': -425.36248779296875, 'eval_logps/rejected': -361.6199951171875, 'eval_logits/chosen': 0.275124728679657, 'eval_logits/rejected': 0.5949507355690002, 'epoch': 0.98}
{'train_runtime': 2713.2378, 'train_samples_per_second': 2.703, 'train_steps_per_second': 0.169, 'train_loss': 0.6074114697691142, 'epoch': 1.0}
2025-10-03 00:28:58,450 - INFO - Saving final model...
